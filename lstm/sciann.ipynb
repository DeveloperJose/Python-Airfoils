{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7a86a5ec4d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mPsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNNFunctional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Psi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlambda1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lambda1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mlambda2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lambda2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/sciann/functionals/parameter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, val, min_max, inputs, name, non_neg)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLPFunctional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import sciann as sn\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "tunits = 3\n",
    "x = sn.functionals.RNNVariable(tunits, 'x', dtype='float64')\n",
    "y = sn.functionals.RNNVariable(tunits, 'y', dtype='float64')\n",
    "t = sn.functionals.RNNVariable(tunits, 't', dtype='float64')\n",
    "\n",
    "P = sn.functionals.RNNFunctional(\"P\", [x, y, t], 8*[20], 'tanh')\n",
    "Psi = sn.functionals.RNNFunctional(\"Psi\", [x, y, t], 8*[20], 'tanh')\n",
    "\n",
    "lambda1 = sn.Parameter(np.random.rand(), inputs=[x,y,t], name=\"lambda1\")\n",
    "lambda2 = sn.Parameter(np.random.rand(), inputs=[x,y,t], name=\"lambda2\")\n",
    "\n",
    "u = sn.diff(Psi, y)\n",
    "v = -sn.diff(Psi, x)\n",
    "\n",
    "u_t = sn.diff(u, t)\n",
    "u_x = sn.diff(u, x)\n",
    "u_y = sn.diff(u, y)\n",
    "u_xx = sn.diff(u, x, order=2)\n",
    "u_yy = sn.diff(u, y, order=2)\n",
    "\n",
    "v_t = sn.diff(v, t)\n",
    "v_x = sn.diff(v, x)\n",
    "v_y = sn.diff(v, y)\n",
    "v_xx = sn.diff(v, x, order=2)\n",
    "v_yy = sn.diff(v, y, order=2)\n",
    "\n",
    "p_x = sn.diff(P, x)\n",
    "p_y = sn.diff(P, y)\n",
    "\n",
    "d1 = sn.Data(u)\n",
    "d2 = sn.Data(v)\n",
    "d3 = sn.Data(P)\n",
    "\n",
    "c1 = sn.Tie(-p_x, u_t+lambda1*(u*u_x+v*u_y)-lambda2*(u_xx+u_yy))\n",
    "c2 = sn.Tie(-p_y, v_t+lambda1*(u*v_x+v*v_y)-lambda2*(v_xx+v_yy))\n",
    "c3 = sn.Data(u_x + v_y)\n",
    "c4 = Psi*0.0\n",
    "\n",
    "model = sn.SciModel(\n",
    "    inputs=[x, y, t],\n",
    "    targets=[d1, d2, d3, c1, c2, c3, c4],\n",
    "    loss_func=\"mse\",\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scaling\n",
    "import data\n",
    "\n",
    "USE_2D = False\n",
    "INPUTS = ['X', 'Y']\n",
    "OUTPUTS = ['Vu', 'Vv', 'P']\n",
    "PREDICT_AHEAD=1\n",
    "NEIGHBOR_SIZE=1\n",
    "LOOKBACK = 1\n",
    "BATCH_SIZE = 5024\n",
    "\n",
    "SCALER_PATH = os.path.join('output', f'scaler_{INPUTS}_2D={USE_2D}.pkl')\n",
    "SCALER_CREATION_DIRS = ['/home/jperez/data/sled250', '/home/jperez/data/sled255']\n",
    "\n",
    "sc = scaling.load_or_create(SCALER_PATH, SCALER_CREATION_DIRS, INPUTS, OUTPUTS, USE_2D)\n",
    "\n",
    "train_generator = data.SledDataGenerator('/home/jperez/data/sled250', batch_size=BATCH_SIZE, lookback=LOOKBACK, predict_ahead=PREDICT_AHEAD, neighbor_size=NEIGHBOR_SIZE, shuffle=True, use_2D=USE_2D, inputs=INPUTS, outputs=OUTPUTS, scaler=sc, \n",
    "                                        start=1, end=510+1)\n",
    "train_generator.sciann = True\n",
    "\n",
    "history = model.train(\n",
    "    x_true=train_generator,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    learning_rate=0.001,\n",
    "    reduce_lr_after=100,\n",
    "    stop_loss_value=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(num_data=5000, random=True):\n",
    "    import scipy.io\n",
    "    # Get data file from: \n",
    "    #         https://github.com/maziarraissi/PINNs/tree/master/main/Data/cylinder_nektar_wake.mat\n",
    "    data = scipy.io.loadmat('cylinder_nektar_wake.mat')\n",
    "    \n",
    "    U_star = data['U_star'] # N x 2 x T\n",
    "    P_star = data['p_star'] # N x T\n",
    "    t_star = data['t'] # T x 1\n",
    "    X_star = data['X_star'] # N x 2\n",
    "    \n",
    "    N = X_star.shape[0]\n",
    "    T = t_star.shape[0]\n",
    "    \n",
    "    # Rearrange Data \n",
    "    XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "    YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "    TT = np.tile(t_star, (1,N)).T # N x T\n",
    "    \n",
    "    UU = U_star[:,0,:] # N x T\n",
    "    VV = U_star[:,1,:] # N x T\n",
    "    PP = P_star # N x T\n",
    "    \n",
    "    # Pick random data.\n",
    "    if random:\n",
    "        idx = np.random.choice(N*T, num_data, replace=False)\n",
    "    else:\n",
    "        idx = np.arange(0, N*T)\n",
    "    \n",
    "    x = XX.flatten()[idx,None] # NT x 1\n",
    "    y = YY.flatten()[idx,None] # NT x 1\n",
    "    t = TT.flatten()[idx,None] # NT x 1\n",
    "    \n",
    "    u = UU.flatten()[idx,None] # NT x 1\n",
    "    v = VV.flatten()[idx,None] # NT x 1\n",
    "    p = PP.flatten()[idx,None] # NT x 1\n",
    " \n",
    "    return (x,y,t,u,v,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1) (5000, 1) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, t_train, u_train, v_train, p_train = PrepareData(5000, random=True)\n",
    "print(x_train.shape, t_train.shape, p_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 638/638 [00:00<00:00, 2056.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ALL_X = []\n",
    "# ALL_Y = []\n",
    "# t_train = []\n",
    "\n",
    "# for timestep in tqdm(range(1, 638+1)):\n",
    "#     X, Y = data.read_np(os.path.join('/home/jperez/data/sled250', f'{timestep}.npy'), INPUTS, OUTPUTS, use_2D=False, scaler=sc)\n",
    "    \n",
    "#     ALL_X.append(X)\n",
    "#     ALL_Y.append(Y)\n",
    "\n",
    "#     tarr = np.zeros((14184, 1))\n",
    "#     tarr[:] = timestep\n",
    "#     t_train.append(tarr)\n",
    "\n",
    "# print(len(ALL_X[0]))\n",
    "# ALL_X = np.array(ALL_X).reshape(-1, len(INPUTS))\n",
    "# ALL_Y = np.array(ALL_Y).reshape(-1, len(OUTPUTS))\n",
    "# t_train = np.array(t_train).reshape(-1, 1)\n",
    "\n",
    "# x_train = ALL_X[:, 0].reshape(-1, 1)\n",
    "# y_train = ALL_X[:, 1].reshape(-1, 1)\n",
    "# u_train = ALL_Y[:, 0].reshape(-1, 1)\n",
    "# v_train = ALL_Y[:, 1].reshape(-1, 1)\n",
    "# p_train = ALL_Y[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362GB of RAM used\n",
      "(9049392, 2) (9049392, 3)\n",
      "(9049392, 1) (9049392, 1) (9049392, 1) (9049392, 1) (9049392, 1) (9049392, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'{(ALL_X.nbytes+ALL_Y.nbytes)/1e9:.3f}GB of RAM used')\n",
    "print(ALL_X.shape, ALL_Y.shape)\n",
    "print(x_train.shape, y_train.shape, t_train.shape, u_train.shape, v_train.shape, p_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [x_train, y_train, t_train]\n",
    "\n",
    "data_d1 = u_train\n",
    "data_d2 = v_train\n",
    "data_d3 = p_train\n",
    "data_c1 = 'zeros'\n",
    "data_c2 = 'zeros'\n",
    "data_c3 = 'zeros'\n",
    "data_c4 = 'zeros'\n",
    "target_data = [data_d1, data_d2, data_d3, data_c1, data_c2, data_c3, data_c4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 9049392 \n",
      "Batch size: 50000 \n",
      "Total batches: 181 \n",
      "\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 99s 452ms/step - batch: 90.0000 - size: 49996.6409 - loss: 1626258388685.7427 - Grad__loss: 25165.5630 - mul_loss: 17243.8531 - P_loss: 1626258346264.6731 - sub_2_loss: 8.4958 - sub_4_loss: 3.1578 - add_7_loss: 6.2228e-29 - mul_12_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 82s 455ms/step - batch: 90.0000 - size: 49996.6409 - loss: 1626282778084.9138 - Grad__loss: 22866.7400 - mul_loss: 16172.1966 - P_loss: 1626282739038.6201 - sub_2_loss: 4.3754 - sub_4_loss: 2.9824 - add_7_loss: 3.7723e-28 - mul_12_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 83s 457ms/step - batch: 90.0000 - size: 49996.6409 - loss: 1626262395324.4712 - Grad__loss: 22238.2944 - mul_loss: 15594.1816 - P_loss: 1626262357484.0249 - sub_2_loss: 3.4817 - sub_4_loss: 4.4890 - add_7_loss: 5.9226e-28 - mul_12_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 83s 457ms/step - batch: 90.0000 - size: 49996.6409 - loss: 1626257837707.9146 - Grad__loss: 21865.9515 - mul_loss: 14811.4990 - P_loss: 1626257801030.0786 - sub_2_loss: 0.2078 - sub_4_loss: 0.1775 - add_7_loss: 9.0364e-28 - mul_12_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      " 12/181 [>.............................] - ETA: 1:17 - batch: 5.5000 - size: 50000.0000 - loss: 1600862518768.8538 - Grad__loss: 21444.0353 - mul_loss: 14543.5747 - P_loss: 1600862482781.0139 - sub_2_loss: 0.0939 - sub_4_loss: 0.1362 - add_7_loss: 1.1467e-27 - mul_12_loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7b6eb42cbcd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/sciann/models/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_true, y_true, weights, target_weights, batch_size, epochs, learning_rate, adaptive_weights, adaptive_sample_weights, log_loss_gradients, shuffle, callbacks, stop_lr_value, reduce_lr_after, reduce_lr_min_delta, stop_after, stop_loss_value, log_parameters, log_functionals, log_loss_landscape, save_weights, default_zero_weight, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;31m# training the models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         history = opt_fit_func(\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0mdata_generator\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# sums to number of samples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    575\u001b[0m     training_utils_v1.check_generator_arguments(\n\u001b[1;32m    576\u001b[0m         y, sample_weight, validation_split=validation_split)\n\u001b[0;32m--> 577\u001b[0;31m     return fit_generator(\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1086\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3956\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.train(\n",
    "    x_true=input_data,\n",
    "    y_true=target_data,\n",
    "    epochs=10,\n",
    "    batch_size=50000,\n",
    "    shuffle=True,\n",
    "    learning_rate=0.001,\n",
    "    reduce_lr_after=100,\n",
    "    stop_loss_value=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lambda1: {},  lambda2: {}\".format(lambda1.value, lambda2.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(history.history['loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbe1d1abaf7dd2ded8faa7720bf0e1d4f69b9081fc349f0d9bde228c06049906"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('keras': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
