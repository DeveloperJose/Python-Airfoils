{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data\n",
    "np.set_printoptions(suppress=True, linewidth=np.inf) \n",
    "\n",
    "# https://blog.nelsonliu.me/2016/07/30/progress-bars-for-python-file-reading-with-tqdm/\n",
    "# This is used for the progress bar so we can keep track of the progress\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    fp.close()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting big CSV file into individual timesteps: 100%|█████████▉| 10542427/10543170 [04:50<00:00, 36280.24it/s, Timestep 760] \n",
      "/home/jperez/miniconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0001.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0002.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0003.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0004.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0005.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0006.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0007.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0008.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0009.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0010.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0011.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0012.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0013.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0014.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0015.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0016.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0017.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0018.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0019.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0020.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0021.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0022.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0023.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0024.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0025.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0026.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0027.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0028.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0029.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0030.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0031.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0032.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0033.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0034.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0035.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0036.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0037.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0038.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0039.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0040.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0041.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0042.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0043.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0044.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0045.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0046.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0047.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0048.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0049.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0050.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0051.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0052.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process timestep in row=['Plane 1 in Case data.300 0053.1']\n",
      "Could not process timestep in row=['Plane 1 in Case data.300 0054.1']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_731229/81286018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# Create dataframe from the data and save it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestep'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    706\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                         \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m                     )\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 590\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             )\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;31m# we will try to copy by-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m#  test_constructor_compound_dtypes, test_constructor_cast_failure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;31m#  test_constructor_dict_cast2, test_loc_setitem_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "input_path = '/home/jperez/data/sled/300.csv'\n",
    "output_dir = '/home/jperez/data/sled300/'\n",
    "columns_to_save = data.COLUMNS_RAW\n",
    "\n",
    "# Overall dataset statistics\n",
    "row_counts = []\n",
    "header_counts = []\n",
    "plane_timesteps = []\n",
    "\n",
    "with open(input_path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    p_bar = tqdm(desc='Splitting big CSV file into individual timesteps', postfix='Timestep 0', total=get_num_lines(input_path))\n",
    "\n",
    "    data_header = []\n",
    "    data_rows = []\n",
    "\n",
    "    prev_timestep = 0\n",
    "\n",
    "    for row in reader:\n",
    "        # Update progress bar\n",
    "        p_bar.update(1)\n",
    "        # Skip empty rows\n",
    "        if len(row) == 0:\n",
    "            continue\n",
    "        # Look for the start of a new file\n",
    "        elif row[0] == '[Name]':\n",
    "            # Check if we have data to save\n",
    "            if len(data_rows) > 0:\n",
    "                # Save some dataset statistics to analyze later\n",
    "                header_counts.append(len(data_header))\n",
    "                row_counts.append(len(data_rows))\n",
    "\n",
    "                # Create dataframe from the data and save it\n",
    "                df = pd.DataFrame(data=data_rows, columns=data_header, dtype=np.float64)\n",
    "                df = df.rename(columns=lambda col: col.strip())\n",
    "                df['Timestep'] = current_timestep\n",
    "\n",
    "                # Save CSV if you want\n",
    "                # df.to_csv(os.path.join(output_dir, f'{prev_timestep}.csv'), index=False, columns=columns_to_save)\n",
    "                \n",
    "                # Saving to NP file format is faster\n",
    "                np.save(os.path.join(output_dir, f'{prev_timestep}'), df[columns_to_save].to_numpy().astype(np.float64))\n",
    "\n",
    "                # Empty data lists for next CSV file\n",
    "                data_header = []\n",
    "                data_rows = []\n",
    "        # Get the data header for this file\n",
    "        elif row[0] == '[Data]':\n",
    "            data_header = next(reader)\n",
    "        # Check what timestep we are on\n",
    "        elif row[0][:5] == 'Plane':\n",
    "            # This will get 00001.250 and split it\n",
    "            ts_split = row[0][-8:].split('.')\n",
    "            # From the split, get the timestep as an integer\n",
    "            try: \n",
    "                current_timestep = int(ts_split[0])\n",
    "            except:\n",
    "                try:\n",
    "                    current_timestep = int(row[0][-4:])\n",
    "                except:\n",
    "                    print(f'Could not process timestep in row={row}')\n",
    "                    current_timestep = None\n",
    "\n",
    "            if current_timestep:\n",
    "                # Compare against previous timestep to see if we jumped more than 1\n",
    "                if current_timestep - prev_timestep > 1:\n",
    "                    print(f'Jumped from timestep {prev_timestep} to timestep {current_timestep}')\n",
    "\n",
    "                # Update variables and progress bar\n",
    "                prev_timestep = current_timestep\n",
    "                plane_timesteps.append(current_timestep)\n",
    "                p_bar.postfix = f'Timestep {current_timestep}'\n",
    "        # Otherwise just collect data rows\n",
    "        else:\n",
    "            data_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Plane 1 in Case FFF']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that all files have the same number of rows [14184]\n",
      "Check that all files have the same header length [22]\n",
      "From 19 to 760\n"
     ]
    }
   ],
   "source": [
    "print('Check that all files have the same number of rows', np.unique(row_counts))\n",
    "print('Check that all files have the same header length', np.unique(header_counts))\n",
    "print(f'From {plane_timesteps[0]} to {plane_timesteps[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14184, 3) (14184, 2)\n",
      "[[  0.           0.25       201.        ]\n",
      " [  0.           0.27500001 201.        ]\n",
      " [ -0.025        0.27500001 201.        ]\n",
      " [ -0.025        0.25       201.        ]\n",
      " [  0.           0.22499999 201.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[249.889465  ,   0.26969039],\n",
       "       [249.883118  ,   0.42404363],\n",
       "       [250.        ,   0.        ],\n",
       "       [250.        ,   0.        ],\n",
       "       [249.901443  ,   0.13346604]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = data.read_np('/home/jperez/data/sled250/201.npy', ['X', 'Y', 'T'], ['Vu', 'Vv'], scaler=None)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print(X[:5])\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14184, 3) (14184, 2)\n",
      "[[ 0.          0.          0.25      ]\n",
      " [ 0.          0.          0.27500001]\n",
      " [-0.025      -0.025       0.27500001]\n",
      " [-0.025      -0.025       0.25      ]\n",
      " [ 0.          0.          0.22499999]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    20.   , 105350.641],\n",
       "       [    20.   , 105225.344],\n",
       "       [    20.   , 105178.828],\n",
       "       [    20.   , 105291.148],\n",
       "       [    20.   , 105422.141]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = data.read_np('/home/jperez/data/sled255/20.npy', ['X', 'Y', 'T'], ['Vu', 'Vv'], scaler=None)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print(X[:5])\n",
    "Y[:5]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbe1d1abaf7dd2ded8faa7720bf0e1d4f69b9081fc349f0d9bde228c06049906"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('keras': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
